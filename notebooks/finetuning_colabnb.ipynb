{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYlr0VNLAnSPnAW/ZpqFiL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/5237-mests/Amharic-E-commerce-Data-Extractor/blob/task-3/notebooks/finetuning_colabnb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning"
      ],
      "metadata": {
        "id": "bt0XUm1Ji3fU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ],
      "metadata": {
        "id": "8FOGnKHujeMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and parse CoNLL format\n",
        "def read_conll_file(filepath):\n",
        "    sentences, labels = [], []\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        sentence, label = [], []\n",
        "        for line_num, line in enumerate(f, 1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                if sentence:\n",
        "                    sentences.append(sentence)\n",
        "                    labels.append(label)\n",
        "                    sentence, label = [], []\n",
        "            else:\n",
        "                parts = line.split()\n",
        "                if len(parts) == 2:\n",
        "                    token, tag = parts\n",
        "                    sentence.append(token)\n",
        "                    label.append(tag)\n",
        "                else:\n",
        "                    print(f\"⚠️ Skipping malformed line {line_num}: {line}\")\n",
        "    return sentences, labels\n"
      ],
      "metadata": {
        "id": "VSubjs9rjiQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize text and align labels\n",
        "def tokenize_and_align_labels(examples, tokenizer, label_to_id):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        aligned_labels = []\n",
        "        previous_word_idx = None\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                aligned_labels.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                aligned_labels.append(label_to_id[label[word_idx]])\n",
        "            else:\n",
        "                aligned_labels.append(label_to_id[label[word_idx]])\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(aligned_labels)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n"
      ],
      "metadata": {
        "id": "fFH7Hcv5j5jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model, tokenizer, label mappings\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "def load_model_and_tokenizer(model_name, num_labels):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "    return tokenizer, model\n"
      ],
      "metadata": {
        "id": "MjDmz2-ukcLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Hugging Face Trainer setup and run\n",
        "from transformers import TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
        "\n",
        "def setup_trainer(model, tokenizer, tokenized_dataset, output_dir=\"./ner-model\", epochs=5):\n",
        "    args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        eval_strategy=\"epoch\",\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=0.01,\n",
        "    )\n",
        "\n",
        "    data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=tokenized_dataset[\"train\"],\n",
        "        eval_dataset=tokenized_dataset[\"test\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "GQjElOOykrHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Datasets"
      ],
      "metadata": {
        "id": "vNH-aMlcjHUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "from datasets import Dataset\n",
        "sentences, tags = read_conll_file(\"ner_data.conll\")\n",
        "data = {\"tokens\": sentences, \"ner_tags\": tags}\n",
        "dataset = Dataset.from_dict(data).train_test_split(test_size=0.2)"
      ],
      "metadata": {
        "id": "t0dEB1kFlhfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp4hyY4el3qQ",
        "outputId": "296fefac-23cc-45d2-bc97-bd37ffa74979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['tokens', 'ner_tags'],\n",
              "        num_rows: 56\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['tokens', 'ner_tags'],\n",
              "        num_rows: 14\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare labels"
      ],
      "metadata": {
        "id": "OZEqwT1OmM92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare labels\n",
        "unique_tags = sorted(set(tag for seq in tags for tag in seq))\n",
        "label_to_id = {tag: i for i, tag in enumerate(unique_tags)}\n",
        "id_to_label = {i: tag for tag, i in label_to_id.items()}"
      ],
      "metadata": {
        "id": "4zWnVMTxmSEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load model"
      ],
      "metadata": {
        "id": "EOAaHahxmY7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model_name = \"xlm-roberta-base\"\n",
        "tokenizer, model = load_model_and_tokenizer(model_name, num_labels=len(unique_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343,
          "referenced_widgets": [
            "4fe6afa3aea249c98de8ea97bbb7e551",
            "db576a8df0fd46d1b484b087da8d4407",
            "9927005a20884fe3915a1bc8ff712fc6",
            "8e55989a0a734a81ad65edb591ebe3fd",
            "599c0db0e0184d928a2775ed4cf16ce9",
            "02e9d4d15c3d42dab96d4617735ba929",
            "9e279a39bf144338867f12fbb3249d56",
            "9cd66511d3734f3abbb6b4de6a125da5",
            "8971615c81bb437e877a84c3669d169c",
            "9a123d9389cf4b6bbbb0587ba1a5d882",
            "b1d6adf31de24596baa0b8c1c93ab990",
            "058d653efd644828956cae90d8578b07",
            "136da42a82624504910101e9a8e0b1fd",
            "f5f38e49c48646eb9ceecdcda3c8b12e",
            "c73cddc9083e4b6c9886b25534224230",
            "7b628941b6c74173901ead46029bbaf5",
            "31024e56e3384361a0997aa0d62c4bdd",
            "8f70ba1d7e9d41818213fb67609beded",
            "2c4c767099b54276ac3e36adff6ee383",
            "f8ea9dd864834232ab15235c4d803a70",
            "a8d880a5cdb345b29d3945adbab788b7",
            "79a34386b886435a8d5d82ad021654b4",
            "ae2fe81c16d2447787547d33d493aa73",
            "59811c1d06a044e1b035ef027cb9a8ad",
            "b2606eca653d460eb9ad668fe71d647c",
            "55b3f74ff924479987ba7a9306d6c261",
            "5a7bcbfaf80b4be7b10f11f5ab3f16c1",
            "0b2a1529e1214ecfb7463900bf84d089",
            "e799e23e9539464a877d5159e8dbd4af",
            "b7fa975f34fa4841ada9521a41bc8c2a",
            "453f7ca87e2a476eb3872fc202ec0ee9",
            "86237702e878401982b5a024979b7a28",
            "2a52f5409a544a369c163cc73f42e9fc",
            "94136cd621904783915a34704440de6e",
            "5b998a96576c4ce8a195ff2672202113",
            "48c57f7170204a538c067e10f6425a5d",
            "ef91df6292be45a7baded86605d9fe55",
            "f142e1249cea4562b5119315a3691411",
            "5d3c3e145e624e3cb2288da43c9d66cd",
            "886b539a0ac74dba95aaa62c73b5d4a3",
            "bf0f261f501940b7b03652cc2dc1c9ac",
            "29840bf4ed434fb78a70af70f281d00f",
            "a2f62842206f455795535ac139336fbf",
            "39a48b6da132458db21a2853e0a0dd08",
            "24569239280a449197ecf1474067a293",
            "24e6cb1fe1a940ad883c79ae3e1cbb79",
            "cc2a4ee05a2147e1b3d093f403808ebd",
            "b2c19e12c32b48de8ff8a80eaa3f9a0b",
            "8eb43caaa41d456a82c74403579aa0a4",
            "c6cf1170ac5941c68c00fcf5f728e334",
            "4f90d8c7e5fd45a1b9bb8dce1c06f4a4",
            "adf2f176dbba44009296220b785df2d2",
            "2991d3d5e5394ff2858c7b2029d48758",
            "e1cdbeb46d2e4f4d9050d66215264763",
            "70312e8f937a4a9a89aad4c3497b9274"
          ]
        },
        "id": "KNWjh-xcmb3J",
        "outputId": "5c53d21b-3f35-473a-91fe-48292085fb7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fe6afa3aea249c98de8ea97bbb7e551"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "058d653efd644828956cae90d8578b07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae2fe81c16d2447787547d33d493aa73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94136cd621904783915a34704440de6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24569239280a449197ecf1474067a293"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize\n",
        "tokenized_dataset = dataset.map(lambda x: tokenize_and_align_labels(x, tokenizer, label_to_id), batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "912e7745d38c4299b3e219a865517801",
            "7f00345cf6284646a650e60868e3e742",
            "5e10f8b84687443f86ba96ebcbdaaaf6",
            "78bb839b0b6c4c12894e98f96e9abebc",
            "4c0ac8989cc640f0bfd31485eed6b395",
            "f9f7400c6955484f82b27c0fe44313f1",
            "bbbce39ebe1846fdbc59989b6dfbabd8",
            "15df706ec9bd42729e3fc12390c36bff",
            "8e147e88f44249b9a40f955a8de0faef",
            "26e9659451eb49208a05c4d97626b46f",
            "1002143c80814601a9f53f7d2ce85759",
            "92fbf4bdd25a46e19026ccd1f80c3c58",
            "e6aed1eee4de482ab496d37bf56acc9a",
            "160d16ddf2ed483a9e02843913507bec",
            "821a5513231e4c12a512774c3b702ee0",
            "8cc1d63d7a724b98b82215f34c299a36",
            "ea40e578f1d042068ea56bd7a0b43b67",
            "2e413fe6e87a49c487d42bd6aabc05fe",
            "864a1814764445e2b47b127b616388ef",
            "07fb54cd8edf461086fe3d0ea4cbfe56",
            "38354714002245f7bb3514848d843d8f",
            "dae3c0803dce49189ed57208b9f7ab21"
          ]
        },
        "id": "Lnl06KmgqAXE",
        "outputId": "c92e1bb9-93f8-4f39-c4b5-2bf736650938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/56 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "912e7745d38c4299b3e219a865517801"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/14 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92fbf4bdd25a46e19026ccd1f80c3c58"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "trainer = setup_trainer(model, tokenizer, tokenized_dataset)\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "3ceEiZK_qI-R",
        "outputId": "aa07efa9-b162-4e12-b347-537186256aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-17-3483684602.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmesfin-7\u001b[0m (\u001b[33mmesfin-7-ml\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250623_072933-fxsebkhm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mesfin-7-ml/huggingface/runs/fxsebkhm' target=\"_blank\">./ner-model</a></strong> to <a href='https://wandb.ai/mesfin-7-ml/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mesfin-7-ml/huggingface' target=\"_blank\">https://wandb.ai/mesfin-7-ml/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mesfin-7-ml/huggingface/runs/fxsebkhm' target=\"_blank\">https://wandb.ai/mesfin-7-ml/huggingface/runs/fxsebkhm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [35/35 16:12, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.227272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.017032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.887153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.860156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.839303</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=35, training_loss=1.0076818193708148, metrics={'train_runtime': 1470.5263, 'train_samples_per_second': 0.19, 'train_steps_per_second': 0.024, 'total_flos': 35815605680448.0, 'train_loss': 1.0076818193708148, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"Evaluation Results:\")\n",
        "eval_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "V-zZqttzyyZc",
        "outputId": "ae2d40e0-d04a-4cc4-ae6e-c659a12b672e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 01:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.8393029570579529,\n",
              " 'eval_runtime': 10.4105,\n",
              " 'eval_samples_per_second': 1.345,\n",
              " 'eval_steps_per_second': 0.192,\n",
              " 'epoch': 5.0}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save models"
      ],
      "metadata": {
        "id": "qZcKtFNtwnLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save\n",
        "trainer.save_model(\"models/xlm-roberta-ner\")\n",
        "tokenizer.save_pretrained(\"models/xlm-roberta-ner\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKzwufH6wuwF",
        "outputId": "9d48fe36-089a-4023-bd54-a72915183734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('models/xlm-roberta-ner/tokenizer_config.json',\n",
              " 'models/xlm-roberta-ner/special_tokens_map.json',\n",
              " 'models/xlm-roberta-ner/sentencepiece.bpe.model',\n",
              " 'models/xlm-roberta-ner/added_tokens.json',\n",
              " 'models/xlm-roberta-ner/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}